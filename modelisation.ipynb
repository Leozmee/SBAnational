{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ Création de caractéristiques avancées\n",
    "# -------------------------------\n",
    "def create_advanced_features(df):\n",
    "    df['loan_per_employee'] = df['GrAppv'] / (df['NoEmp'] + 1)\n",
    "    df['job_creation_rate'] = (df['CreateJob'] + df['RetainedJob']) / (df['NoEmp'] + 1)\n",
    "    \n",
    "    df['term_amount_ratio'] = df['GrAppv'] / df['Term'].replace(0, np.nan)\n",
    "    \n",
    "    state_default_rates = df.groupby('State')['MIS_Status'].mean()\n",
    "    df['state_risk'] = df['State'].map(state_default_rates)\n",
    "    \n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Appliquer la transformation\n",
    "df = create_advanced_features(df)\n",
    "\n",
    "# Séparation des features et de la target\n",
    "X = df.drop(columns=['MIS_Status'])\n",
    "y = df['MIS_Status']\n",
    "\n",
    "# Définition des variables catégorielles\n",
    "cat_features = ['State', 'NewExist', 'UrbanRural', 'FranchiseCode', 'NAICS', 'ApprovalFY','crysis_year']\n",
    "\n",
    "# Séparation en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "\n",
    "# Convertir les colonnes catégorielles en string\n",
    "X_train[cat_features] = X_train[cat_features].astype(str)\n",
    "X_test[cat_features] = X_test[cat_features].astype(str)\n",
    "\n",
    "# Vérifier si les colonnes catégorielles existent bien\n",
    "for col in cat_features:\n",
    "    if col not in X_train.columns:\n",
    "        print(f\"⚠️ Attention: {col} n'est pas présent dans X_train.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Grid Search optimisé\n",
    "# -------------------------------\n",
    "param_grid = {\n",
    "    'depth': [4, 5, 6],  \n",
    "    'grow_policy': ['Lossguide'],  \n",
    "    'l2_leaf_reg': [0.5, 0.6, 0.7],  \n",
    "    'learning_rate': [0.16, 0.18, 0.20],  \n",
    "    'scale_pos_weight': [1]  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=CatBoostClassifier(\n",
    "        iterations=500,  \n",
    "        loss_function='Logloss',\n",
    "        cat_features=cat_features,\n",
    "        early_stopping_rounds=50,  \n",
    "        verbose=200  \n",
    "    ),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  \n",
    "    scoring='roc_auc',\n",
    "    verbose=3,\n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "# Exécution du GridSearch\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres\n",
    "print(\"Meilleurs paramètres après GridSearch :\", grid_search.best_params_)\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Réentraînement avec les meilleurs paramètres\n",
    "# -------------------------------\n",
    "best_model = CatBoostClassifier(\n",
    "    **grid_search.best_params_,\n",
    "    iterations=1000,  \n",
    "    loss_function='Logloss',\n",
    "    cat_features=cat_features,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_test, y_test),\n",
    "    use_best_model=True,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Prédictions avec seuil personnalisé (0.3)\n",
    "# -------------------------------\n",
    "# Probabilités de prédiction\n",
    "y_pred_proba_train = best_model.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Définition du seuil\n",
    "seuil = 0.3\n",
    "\n",
    "# Conversion en classes en fonction du seuil\n",
    "y_pred_train_custom = (y_pred_proba_train >= seuil).astype(int)\n",
    "y_pred_test_custom = (y_pred_proba_test >= seuil).astype(int)\n",
    "\n",
    "# Affichage des premières valeurs\n",
    "print(\"📊 Exemple de prédictions avec seuil personnalisé :\")\n",
    "print(\"Train:\", y_pred_train_custom[:10])\n",
    "print(\"Test:\", y_pred_test_custom[:10])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
